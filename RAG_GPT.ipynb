{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8MbwDTbRHdxE"},"outputs":[],"source":["!pip -q install langchain pypdf chromadb sentence-transformers faiss-gpu rank_bm25\n","!pip install datasets\n","!pip install jq\n","!pip install openai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1xLiJVOqiQa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712818725590,"user_tz":-540,"elapsed":23547,"user":{"displayName":"김민창","userId":"14228720808257313870"}},"outputId":"9de18b3b-5856-4828-9e91-4943d6cd49b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VCf7rbA0qD-b"},"outputs":[],"source":["## gpt로 바꾸려면 bnb_config지우고 model_id를 huggingface에서 찾아서 id로 넣고 하면 되지 않을까요?\n","import torch\n","from langchain.llms import HuggingFacePipeline\n","import os\n","from langchain.chat_models import ChatOpenAI\n","os.environ[\"OPENAI_API_KEY\"]=\"\"\n","\n","\n","## Gemma 불러오고 토크나이저 불러오고 양자화 시키는 코드 ##\n","llm = ChatOpenAI(model_name=\"gpt-4-turbo\",temperature=0)"]},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","## prompt 설정해주는 코드 안넣고 싶었는데 이걸 넣어야 코드가 진행되서 넣었음\n","prompt_template = \"\"\"\n","\"Answer the following questions in one or two or three word.\"\n","### CONTEXT ###\n","{context}\n","\n","### QUESTION ###\n","{question}\n"," \"\"\"\n","prompt = PromptTemplate(\n","  input_variables=[\"context\", \"question\"],\n","  template=prompt_template\n",")"],"metadata":{"id":"lIU0gk1vIRTB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nfMeoV3hPVtk","collapsed":true},"outputs":[],"source":["from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n","from langchain.vectorstores import FAISS\n","from langchain_community.retrievers import BM25Retriever\n","from langchain.retrievers import EnsembleRetriever\n","## 벡터 임베딩 모델 불러오고 'context'저장된 파일 text split한 후 FAISS 벡터 저장소에 임베딩 시킨 벡터 저장\n","embed_model_id=\"sentence-transformers/all-MiniLM-L6-v2\"\n","embeddings = HuggingFaceEmbeddings(model_name=embed_model_id,model_kwargs={\"device\":\"cuda\"})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXzD5AKEmO6C"},"outputs":[],"source":["import re\n","import string\n","import collections\n","## EM Score / F1 Score 계산하기 위한 코드\n","def normalize_answer(s):\n","  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","  def remove_articles(text):\n","    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n","    return re.sub(regex, ' ', text)\n","  def white_space_fix(text):\n","    return ' '.join(text.split())\n","  def remove_punc(text):\n","    exclude = set(string.punctuation)\n","    return ''.join(ch for ch in text if ch not in exclude)\n","  def lower(text):\n","    return text.lower()\n","  return white_space_fix(remove_articles(remove_punc(lower(s))))\n","def get_tokens(s):\n","  if not s: return []\n","  return normalize_answer(s).split()\n","\n","def compute_exact(a_gold, a_pred):\n","  return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n","\n","def compute_f1(a_gold, a_pred):\n","  if a_pred == -1:\n","    return -1\n","  gold_toks = get_tokens(a_gold)\n","  pred_toks = get_tokens(a_pred)\n","  common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n","  num_same = sum(common.values())\n","  if len(gold_toks) == 0 or len(pred_toks) == 0:\n","    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n","    return int(gold_toks == pred_toks)\n","  if num_same == 0:\n","    return 0\n","  precision = 1.0 * num_same / len(pred_toks)\n","  recall = 1.0 * num_same / len(gold_toks)\n","  f1 = (2 * precision * recall) / (precision + recall)\n","  return f1"]},{"cell_type":"code","source":["from langchain.schema.runnable import RunnablePassthrough\n","from datasets import load_dataset\n","from langchain.schema.runnable import RunnableMap\n","import numpy as np\n","from langchain.chains import RetrievalQA\n","from langchain.docstore.document import Document\n","dataset = load_dataset('trivia_qa','unfiltered')\n","test_data = dataset['validation']"],"metadata":{"id":"vRoyFyFfjlqz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import openai\n","exact_scores=[]\n","f1_scores=0\n","i=1\n","for item in test_data:\n","    text_groups=[]\n","    question = item[\"question\"]\n","    try:\n","      context = item['search_results']['search_context'][0]\n","    except IndexError:\n","      continue\n","    answer_list = item[\"answer\"]['aliases']\n","    lines = context.split('\\n')\n","    for j in range(0,len(lines),4):\n","      text_groups.append('. '.join(lines[j:j+4]))\n","    text_groups = np.array(text_groups)\n","    doc = [Document(page_content=text, metadata={\"source\": \"local\"}) for text in text_groups]\n","    db = FAISS.from_documents(doc, embeddings)\n","    faiss_retriever = db.as_retriever(\n","                            search_type=\"similarity\",\n","                            search_kwargs={'k': 3}\n","                            )\n","    qa_chain = RetrievalQA.from_chain_type(\n","        llm=llm,\n","        chain_type=\"stuff\",\n","        retriever=faiss_retriever,\n","        return_source_documents=True,\n","        chain_type_kwargs={\"prompt\": prompt}\n","    )\n","    try:\n","        result = qa_chain.invoke(question)\n","        answer_pred = result['result']\n","    except openai.RateLimitError as e:\n","        print(f\"Rate limit exceeded: {e}\")\n","        continue\n","    answer_pred = result['result']\n","    f1_score=-1\n","    for answer in answer_list:\n","      score = compute_f1(answer,answer_pred)\n","      if score>f1_score:\n","        print(f\"{answer} = {answer_pred} : {score}\")\n","        f1_score=score\n","    if f1_score!=-1:\n","      i=i+1\n","      f1_scores+=f1_score\n","    else:\n","      i=i-1\n","      if i==0:\n","        i=1\n","    print(i)\n","    print(f\"정답 : {answer}\")\n","    print(f\"예측 : {answer_pred}\")\n","    print(f1_score)\n","    print(f1_scores/i)"],"metadata":{"id":"oIbrnnakiAKI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0rUW7ghriVMY"},"outputs":[],"source":["from langchain.schema.runnable import RunnablePassthrough\n","from datasets import load_dataset\n","from langchain.schema.runnable import RunnableMap\n","import numpy as np\n","from langchain.chains import RetrievalQA\n","from langchain.docstore.document import Document\n","dataset = load_dataset('squad',split='validation')\n","exact_scores=0\n","f1_scores=0\n","i=0\n","\n","for item in dataset:\n","    i=i+1\n","    question = item[\"question\"]\n","    answer = item[\"answers\"][\"text\"][0]\n","\n","    texts = item['context'].split('.')\n","    doc =  [Document(page_content=text, metadata={\"source\": \"local\"}) for text in texts]\n","    db = FAISS.from_documents(doc, embeddings)\n","    faiss_retriever = db.as_retriever(\n","                            search_type=\"similarity\",\n","                            search_kwargs={'k': 2}\n","                            )\n","    qa_chain = RetrievalQA.from_chain_type(\n","        llm=llm,\n","        chain_type=\"stuff\",\n","        retriever=faiss_retriever,\n","        return_source_documents=True,\n","        chain_type_kwargs={\"prompt\": prompt}\n","    )\n","    result = qa_chain(question)\n","    print(result['result'])\n","    answer_pred = result['result']\n","\n","    ## EM Score/F1 Score 계산\n","    exact_score = compute_exact(answer,answer_pred)\n","    f1_score = compute_f1(answer,answer_pred)\n","    if f1_score!=-1:\n","      f1_scores+=f1_score\n","    print(i)\n","    print(f\"정답 : {answer}\")\n","    print(f\"예측 : {answer_pred}\")\n","    print(f1_score)\n","    print(f1_scores/i)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"g1zF16S99TVG"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1jxv97MLscakCv_hGmpb4EWlV0PyY5tl8","timestamp":1712817876245},{"file_id":"1mHjbjCjlCgojB59sxdbUg5qy2RFV3ktC","timestamp":1712727902562}],"mount_file_id":"1enofnBO61lKjzMcnq8ZoRHNtwRLFjTyP","authorship_tag":"ABX9TyMZYGRwI+Q1dtRcGNLJi9Hx"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}